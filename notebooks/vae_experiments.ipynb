{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NVAE Experiment on CIFAR-10\n",
        "\n",
        "This notebook implements the training and evaluation pipeline for the Nouveau VAE (NVAE) model on CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Google Colab Setup\n",
        "Mount Drive and clone the repository (Fresh Copy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "REPO_PATH = '/content/drive/MyDrive/Generative-Modeling-on-CIFAR-10'\n",
        "REPO_URL = \"https://github.com/konstantine25b/Generative-Modeling-on-CIFAR-10.git\"\n",
        "\n",
        "# 1. Delete repo if it already exists (Ensure fresh code)\n",
        "if os.path.exists(REPO_PATH):\n",
        "    print(f\"Deleting existing repository at {REPO_PATH}...\")\n",
        "    shutil.rmtree(REPO_PATH)\n",
        "\n",
        "# 2. Clone repository\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "print(f\"Cloning repository to {REPO_PATH}...\")\n",
        "!git clone {REPO_URL}\n",
        "\n",
        "# 3. Enter the repository\n",
        "os.chdir(REPO_PATH)\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# 4. Add source code to Python path\n",
        "sys.path.append(os.path.join(REPO_PATH, 'src'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GitHub Configuration (Optional)\n",
        "Configure this if you want to push results back to the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHub Configuration & Setup\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # 1. Configure Git\n",
        "    user_name = \"konstantine25b\"\n",
        "    mail = \"konstantine25b@gmail.com\"\n",
        "\n",
        "    # --- IMPORTANT: PASTE YOUR TOKEN BELOW ---\n",
        "    my_token = \"YOUR_TOKEN_HERE\"\n",
        "\n",
        "    if my_token == \"YOUR_TOKEN_HERE\":\n",
        "        print(\"⚠️ PLEASE UPDATE 'my_token' in the code cell with your actual GitHub token to enable pushing.\")\n",
        "\n",
        "    repo_url = f\"https://{my_token}@github.com/konstantine25b/Generative-Modeling-on-CIFAR-10.git\"\n",
        "\n",
        "    !git config --global user.name \"{user_name}\"\n",
        "    !git config --global user.email \"{mail}\"\n",
        "\n",
        "    # 2. Set Remote URL\n",
        "    if os.path.isdir(\".git\") and my_token != \"YOUR_TOKEN_HERE\":\n",
        "        !git remote set-url origin \"{repo_url}\"\n",
        "        print(\"Git configured successfully for pushing.\")\n",
        "    else:\n",
        "        print(\"Skipping remote setup (either not a git repo or token not set).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up GitHub: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install wandb -q\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from src.utils.data_loader import get_cifar10_loaders\n",
        "from src.vae.train import train_vae\n",
        "from src.vae.sampling import generate_samples, save_sample_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import wandb\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'epochs': 50,\n",
        "    'batch_size': 64,\n",
        "    'lr': 1e-3,\n",
        "    'hidden_dim': 64,\n",
        "    'latent_dim': 20,\n",
        "    'num_scales': 2,\n",
        "    'warmup_epochs': 5,\n",
        "    'weight_decay': 3e-4,\n",
        "    'use_wandb': True, # Set to True if using WandB\n",
        "    # Save checkpoints OUTSIDE the repo folder to avoid deletion during re-runs\n",
        "    'model_save_dir': '/content/drive/MyDrive/Generative-Modeling-on-CIFAR-10-Checkpoints/nvae_exp1',\n",
        "    'results_dir': 'results/'\n",
        "}\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(config['model_save_dir'], exist_ok=True)\n",
        "os.makedirs(config['results_dir'], exist_ok=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Checkpoints will be saved to: {config['model_save_dir']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader = get_cifar10_loaders(\n",
        "    data_dir='./data', \n",
        "    batch_size=config['batch_size']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Training\n",
        "train_vae(config, train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Final Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.vae.train import evaluate\n",
        "from src.vae.model import NVAE\n",
        "\n",
        "# 1. Load the best model\n",
        "best_model = NVAE(\n",
        "    hidden_dim=config['hidden_dim'],\n",
        "    latent_dim=config['latent_dim'],\n",
        "    num_scales=config['num_scales']\n",
        ").to(device)\n",
        "\n",
        "best_model_path = os.path.join(config['model_save_dir'], 'nvae_best.pth')\n",
        "best_model.load_state_dict(torch.load(best_model_path))\n",
        "print(f\"Loaded best model from {best_model_path}\")\n",
        "\n",
        "# 2. Evaluate on Test Set\n",
        "test_loss, test_bpd = evaluate(best_model, test_loader, device)\n",
        "print(f\"Final Test Set Results -> Loss: {test_loss:.4f} | BPD: {test_bpd:.4f}\")\n",
        "\n",
        "# 3. Log to WandB\n",
        "if wandb.run is not None:\n",
        "    wandb.log({\n",
        "        \"test/final_loss\": test_loss,\n",
        "        \"test/final_bpd\": test_bpd\n",
        "    })\n",
        "    print(\"Logged test results to WandB.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Generate Samples & Log to WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model (automatically saved during training)\n",
        "from src.vae.model import NVAE\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "model = NVAE(\n",
        "    hidden_dim=config['hidden_dim'],\n",
        "    latent_dim=config['latent_dim'],\n",
        "    num_scales=config['num_scales']\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(config['model_save_dir'], 'nvae_best.pth')))\n",
        "print(\"Loaded best model.\")\n",
        "\n",
        "# Generate\n",
        "samples = generate_samples(model, num_samples=64, temperature=0.8, device=device)\n",
        "\n",
        "# Visualize locally\n",
        "plt.figure(figsize=(10, 10))\n",
        "grid_img = vutils.make_grid(samples, nrow=8, normalize=True)\n",
        "plt.imshow(grid_img.permute(1, 2, 0).cpu().numpy())\n",
        "plt.axis('off')\n",
        "plt.title(\"Generated Samples (T=0.8)\")\n",
        "plt.show()\n",
        "\n",
        "# Log to WandB if active\n",
        "if wandb.run is not None:\n",
        "    wandb.log({\n",
        "        \"final_evaluation/generated_samples_grid\": [wandb.Image(grid_img, caption=\"Final Generated Samples (T=0.8)\")]\n",
        "    })\n",
        "    print(\"Logged final samples to WandB.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
