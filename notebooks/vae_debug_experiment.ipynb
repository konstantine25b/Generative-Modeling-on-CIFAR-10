{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NVAE Debug Experiment (Fast Run)\n",
        "\n",
        "This is a DEBUG version of the experiment notebook. It uses a **subset of data (10%)** and **fewer epochs** to ensure the pipeline works quickly (under 30 mins)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Google Colab Setup\n",
        "Mount Drive and clone the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "REPO_PATH = '/content/drive/MyDrive/Generative-Modeling-on-CIFAR-10'\n",
        "REPO_URL = \"https://github.com/konstantine25b/Generative-Modeling-on-CIFAR-10.git\"\n",
        "\n",
        "# 1. Clone if not exists\n",
        "if not os.path.exists(REPO_PATH):\n",
        "    print(f\"Cloning repository to {REPO_PATH}...\")\n",
        "    os.chdir('/content/drive/MyDrive')\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_PATH}\")\n",
        "\n",
        "# 2. Enter the repository\n",
        "os.chdir(REPO_PATH)\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# 3. Add source code to Python path\n",
        "sys.path.append(os.path.join(REPO_PATH, 'src'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GitHub Configuration (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHub Configuration & Setup\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # 1. Configure Git\n",
        "    user_name = \"konstantine25b\"\n",
        "    mail = \"konstantine25b@gmail.com\"\n",
        "\n",
        "    # --- IMPORTANT: PASTE YOUR TOKEN BELOW ---\n",
        "    my_token = \"YOUR_TOKEN_HERE\"\n",
        "\n",
        "    if my_token == \"YOUR_TOKEN_HERE\":\n",
        "        print(\"⚠️ PLEASE UPDATE 'my_token' in the code cell with your actual GitHub token to enable pushing.\")\n",
        "\n",
        "    repo_url = f\"https://{my_token}@github.com/konstantine25b/Generative-Modeling-on-CIFAR-10.git\"\n",
        "\n",
        "    !git config --global user.name \"{user_name}\"\n",
        "    !git config --global user.email \"{mail}\"\n",
        "\n",
        "    # 2. Set Remote URL\n",
        "    if os.path.isdir(\".git\") and my_token != \"YOUR_TOKEN_HERE\":\n",
        "        !git remote set-url origin \"{repo_url}\"\n",
        "        print(\"Git configured successfully for pushing.\")\n",
        "    else:\n",
        "        print(\"Skipping remote setup (either not a git repo or token not set).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up GitHub: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install wandb -q\n",
        "# !wandb login # Uncomment to login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup DEBUG Experiment (Fast Config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from src.utils.data_loader import get_cifar10_loaders\n",
        "from src.vae.train import train_vae\n",
        "from src.vae.sampling import generate_samples, save_sample_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "# DEBUG Configuration\n",
        "config = {\n",
        "    'epochs': 5,          # Reduced from 50 to 5 for speed\n",
        "    'batch_size': 64,\n",
        "    'lr': 1e-3,\n",
        "    'hidden_dim': 64,\n",
        "    'latent_dim': 20,\n",
        "    'num_scales': 2,\n",
        "    'warmup_epochs': 2,   # Reduced warmup\n",
        "    'weight_decay': 3e-4,\n",
        "    'use_wandb': False,   # Set to True if you want to test logging too\n",
        "    'run_name': 'nvae_debug_run',\n",
        "    'model_save_dir': 'models/debug',\n",
        "    'results_dir': 'results/debug'\n",
        "}\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(config['model_save_dir'], exist_ok=True)\n",
        "os.makedirs(config['results_dir'], exist_ok=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load SUBSET of Data\n",
        "We wrap the data loader to use only 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Get full datasets first\n",
        "# We use a trick: get the loaders, then access their datasets\n",
        "full_train_loader, full_val_loader, full_test_loader = get_cifar10_loaders(\n",
        "    data_dir='./data', \n",
        "    batch_size=config['batch_size']\n",
        ")\n",
        "\n",
        "# Function to create subset loader\n",
        "def create_subset_loader(original_loader, fraction=0.1):\n",
        "    dataset = original_loader.dataset\n",
        "    subset_size = int(len(dataset) * fraction)\n",
        "    # Just take the first N indices for determinism\n",
        "    indices = list(range(subset_size))\n",
        "    subset = Subset(dataset, indices)\n",
        "    \n",
        "    return DataLoader(\n",
        "        subset, \n",
        "        batch_size=original_loader.batch_size, \n",
        "        shuffle=True if original_loader.dataset == full_train_loader.dataset else False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "# Create 10% subsets\n",
        "print(\"Creating 10% data subsets for fast debugging...\")\n",
        "train_loader = create_subset_loader(full_train_loader, fraction=0.1)\n",
        "val_loader = create_subset_loader(full_val_loader, fraction=0.2) # 20% of val set\n",
        "\n",
        "print(f\"Debug Train Loader: {len(train_loader)} batches (approx {len(train_loader.dataset)} images)\")\n",
        "print(f\"Debug Val Loader: {len(val_loader)} batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Model (Fast Run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Training\n",
        "train_vae(config, train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "from src.vae.model import NVAE\n",
        "\n",
        "model = NVAE(\n",
        "    hidden_dim=config['hidden_dim'],\n",
        "    latent_dim=config['latent_dim'],\n",
        "    num_scales=config['num_scales']\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(config['model_save_dir'], 'nvae_best.pth')))\n",
        "print(\"Loaded best model.\")\n",
        "\n",
        "# Generate\n",
        "samples = generate_samples(model, num_samples=64, temperature=0.8, device=device)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 10))\n",
        "grid_img = torchvision.utils.make_grid(samples, nrow=8, normalize=True)\n",
        "plt.imshow(grid_img.permute(1, 2, 0).cpu().numpy())\n",
        "plt.axis('off')\n",
        "plt.title(\"Generated Samples (Debug Run)\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
