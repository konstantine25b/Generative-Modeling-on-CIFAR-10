{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NVAE Debug Experiment with WandB & Overfitting Check\n",
        "\n",
        "This debug notebook tests:\n",
        "1. **WandB Logging**: Ensures metrics and images are logged correctly.\n",
        "2. **Overfitting**: Uses the training set as the validation set to verify the model can learn.\n",
        "3. **Config**: 10 Epochs, Subset of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Google Colab Setup\n",
        "Mount Drive and clone the repository (Fresh Copy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "REPO_PATH = '/content/drive/MyDrive/Generative-Modeling-on-CIFAR-10'\n",
        "REPO_URL = \"https://github.com/konstantine25b/Generative-Modeling-on-CIFAR-10.git\"\n",
        "\n",
        "# 1. Delete repo if it already exists (Ensure fresh code)\n",
        "if os.path.exists(REPO_PATH):\n",
        "    print(f\"Deleting existing repository at {REPO_PATH}...\")\n",
        "    shutil.rmtree(REPO_PATH)\n",
        "\n",
        "# 2. Clone repository\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "print(f\"Cloning repository to {REPO_PATH}...\")\n",
        "!git clone {REPO_URL}\n",
        "\n",
        "# 3. Enter the repository\n",
        "os.chdir(REPO_PATH)\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# 4. Add source code to Python path\n",
        "sys.path.append(os.path.join(REPO_PATH, 'src'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GitHub & WandB Configuration\n",
        "**Important:** You need your WandB API key here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GitHub Configuration & Setup\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # 1. Configure Git\n",
        "    user_name = \"konstantine25b\"\n",
        "    mail = \"konstantine25b@gmail.com\"\n",
        "\n",
        "    # --- IMPORTANT: PASTE YOUR TOKEN BELOW ---\n",
        "    my_token = \"YOUR_TOKEN_HERE\"\n",
        "\n",
        "    if my_token == \"YOUR_TOKEN_HERE\":\n",
        "        print(\"⚠️ PLEASE UPDATE 'my_token' in the code cell with your actual GitHub token to enable pushing.\")\n",
        "\n",
        "    repo_url = f\"https://{my_token}@github.com/konstantine25b/Generative-Modeling-on-CIFAR-10.git\"\n",
        "\n",
        "    !git config --global user.name \"{user_name}\"\n",
        "    !git config --global user.email \"{mail}\"\n",
        "\n",
        "    # 2. Set Remote URL\n",
        "    if os.path.isdir(\".git\") and my_token != \"YOUR_TOKEN_HERE\":\n",
        "        !git remote set-url origin \"{repo_url}\"\n",
        "        print(\"Git configured successfully for pushing.\")\n",
        "    else:\n",
        "        print(\"Skipping remote setup (either not a git repo or token not set).\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up GitHub: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install wandb -q\n",
        "\n",
        "# Login to WandB\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup WandB Test Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from src.utils.data_loader import get_cifar10_loaders\n",
        "from src.vae.train import train_vae\n",
        "from src.vae.sampling import generate_samples, save_sample_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "# WandB Test Configuration\n",
        "config = {\n",
        "    'epochs': 10,         # Increased to 10\n",
        "    'batch_size': 64,\n",
        "    'lr': 1e-3,\n",
        "    'hidden_dim': 64,\n",
        "    'latent_dim': 20,\n",
        "    'num_scales': 2,\n",
        "    'warmup_epochs': 3,\n",
        "    'weight_decay': 3e-4,\n",
        "    'use_wandb': True,    # ENABLED WandB\n",
        "    'run_name': 'nvae_debug_wandb_test',\n",
        "    'model_save_dir': 'models/debug_wandb',\n",
        "    'results_dir': 'results/debug_wandb'\n",
        "}\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(config['model_save_dir'], exist_ok=True)\n",
        "os.makedirs(config['results_dir'], exist_ok=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Data (Train set used as Val set)\n",
        "We use a subset of the training data for both training AND validation to check for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "full_train_loader, _, _ = get_cifar10_loaders(\n",
        "    data_dir='./data', \n",
        "    batch_size=config['batch_size']\n",
        ")\n",
        "\n",
        "# Create a small subset of training data (e.g., 2000 images)\n",
        "def create_subset_loader(original_loader, size=2000):\n",
        "    dataset = original_loader.dataset\n",
        "    indices = list(range(size))\n",
        "    subset = Subset(dataset, indices)\n",
        "    \n",
        "    return DataLoader(\n",
        "        subset, \n",
        "        batch_size=original_loader.batch_size, \n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "# Create ONE subset loader\n",
        "subset_loader = create_subset_loader(full_train_loader, size=5000)\n",
        "\n",
        "# Use the SAME loader for both Train and Test to check overfitting capability\n",
        "train_loader = subset_loader\n",
        "val_loader = subset_loader \n",
        "\n",
        "print(f\"Using same subset ({len(train_loader.dataset)} images) for Train and Val.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Model (WandB Enabled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Training\n",
        "train_vae(config, train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Samples & Log to WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "from src.vae.model import NVAE\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "model = NVAE(\n",
        "    hidden_dim=config['hidden_dim'],\n",
        "    latent_dim=config['latent_dim'],\n",
        "    num_scales=config['num_scales']\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(config['model_save_dir'], 'nvae_best.pth')))\n",
        "print(\"Loaded best model.\")\n",
        "\n",
        "# Generate\n",
        "samples = generate_samples(model, num_samples=64, temperature=0.8, device=device)\n",
        "\n",
        "# Visualize locally\n",
        "plt.figure(figsize=(10, 10))\n",
        "grid_img = vutils.make_grid(samples, nrow=8, normalize=True)\n",
        "plt.imshow(grid_img.permute(1, 2, 0).cpu().numpy())\n",
        "plt.axis('off')\n",
        "plt.title(\"Generated Samples (WandB Test)\")\n",
        "plt.show()\n",
        "\n",
        "# Log to WandB if active\n",
        "if wandb.run is not None:\n",
        "    wandb.log({\n",
        "        \"final_evaluation/generated_samples_grid\": [wandb.Image(grid_img, caption=\"Final Generated Samples (T=0.8)\")]\n",
        "    })\n",
        "    print(\"Logged final samples to WandB.\")\n",
        "    wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
